{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw6_rf_boosting",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcKcZehxxy_j"
      },
      "source": [
        "# Homework 6\n",
        "\n",
        "In this homework I will explore a subset of the Ames Housing Dataset which is available on Kaggle. In order to reduce the length of parameter tuning and data cleaning I'll use a smaller subset of predictors. I'm accessing this data through the Kaggle API to save space on my computer. I'll implement an Elastic Net, Linear Regression, KNN Regression, Random Forest, and Gradient-Boosting Machine. Most of the code below is data acquisition and cleaning, I'll add comments where necessary but this can largely be skipped.\n",
        "\n",
        "\n",
        "\n",
        "The Ames Housing Dataset is a famous dataset in machine learning with over 80 columns which characterize houses. The size of the lot, number of bathrooms, and house's sale price are some of the variables included. The training and testing data were accessed from [this](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) Kaggle competition. The Kaggle page has a detailed outline of the data, but the only variables I'll use are the following:\n",
        "\n",
        "\n",
        "SalePrice - the property's sale price in dollars. This is the target variable that I'm trying to predict.\n",
        "\n",
        "LotArea: Lot size in square feet\n",
        "\n",
        "BldgType: Type of dwelling\n",
        "\n",
        "HouseStyle: Style of dwelling\n",
        "\n",
        "YearBuilt: Original construction date\n",
        "\n",
        "Heating: Type of heating\n",
        "\n",
        "CentralAir: Central air conditioning\n",
        "\n",
        "FullBath: Full bathrooms above grade\n",
        "\n",
        "HalfBath: Half baths above grade\n",
        "\n",
        "Fireplaces: Number of fireplaces\n",
        "\n",
        "GarageArea: Size of garage in square feet\n",
        "\n",
        "PoolArea: Pool area in square feet\n",
        "\n",
        "YrSold: Year Sold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YxkBIPq_hfE"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "K0M4CgjGBNTm",
        "outputId": "2b8d748e-8b99-4f42-ac19-b2f599383b26"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "# import kaggle API token w/ upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-091f48f2-c417-4314-9cea-dceaabfa1fbb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-091f48f2-c417-4314-9cea-dceaabfa1fbb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"calvinsmith625\",\"key\":\"c40d4b53983a1207856bd7b6391516f2\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB8gb93nBNRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db36be0-e2b3-459b-d945-b6a8d9895969"
      },
      "source": [
        "# create local directory called kaggle\n",
        "! mkdir ~/.kaggle\n",
        "# add kaggle.json token to that directory\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e6fRUvTBNO5"
      },
      "source": [
        "# change permissions of folder\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNlx1jx-BNL_",
        "outputId": "b92e2cde-6ae6-45ff-bb66-552c00b71c40"
      },
      "source": [
        "# check my access to the kaggle API\n",
        "! kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                         title                                              size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              221KB  2021-03-28 09:42:48           1148  \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-02-17 16:10:44            866  \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   1GB  2021-02-18 10:08:27            743  \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19            324  \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-03-16 22:31:35            133  \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39             31  \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00            259  \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52             86  \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04             50  \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23            158  \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54             63  \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51             41  \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            113  \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54             26  \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40             24  \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26             23  \n",
            "shivamb/netflix-shows                                       Netflix Movies and TV Shows                         1MB  2021-01-18 16:20:26         122499  \n",
            "jsphyg/weather-dataset-rattle-package                       Rain in Australia                                   4MB  2020-12-11 10:26:12          41655  \n",
            "arashnic/hr-analytics-job-change-of-data-scientists         HR Analytics: Job Change of Data Scientists       295KB  2020-12-07 00:25:10          17251  \n",
            "michau96/restaurant-business-rankings-2020                  Restaurant Business Rankings 2020                  16KB  2021-01-30 14:20:45          10811  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd0KpAH-ATWM",
        "outputId": "d775cc49-2177-4874-d2d9-c041c3831a4b"
      },
      "source": [
        "# load desired dataset\n",
        "! kaggle competitions download -c house-prices-advanced-regression-techniques\n",
        "# this will make the data available in the files panel, in other cases it may need to be unzipped"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "data_description.txt: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8UcSxnkCXfc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zAu3DRwCfzT",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "002685b1-fecd-4496-cec0-f77a88ee5257"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "files.upload()\n",
        "test_answers = pd.read_csv('solution.csv')\n",
        "# must append the testing data's true value from another source and combine to the full dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd9b42c7-8a5f-4d75-910c-cab16fd7cf5a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fd9b42c7-8a5f-4d75-910c-cab16fd7cf5a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving solution.csv to solution (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "ssqx-3inDA85",
        "outputId": "b3bd3fe5-d529-4c92-bf20-3a21a4d3ffcd"
      },
      "source": [
        "display(train.shape, test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(1460, 81)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(1459, 80)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVtusFFRUWlp"
      },
      "source": [
        "test = test.merge(test_answers,\n",
        "           how='left',\n",
        "           on='Id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu_HdFPQVAMh"
      },
      "source": [
        "data = pd.concat([train, test], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTu-NbIu9JF2"
      },
      "source": [
        "I'll only use the columns below for simplicity sake. There were over 80 variables in the dataset. I've broken it down to the few below. The categorical variables require one-hot encoding and I'll perform that below. Pandas' get_dummies() function will create a dummy variable for each variable less one in each categorical column. The drop_first argument ensures drops one of the cateogires. Therefore, the CentralAir column will be a binary variable where 1 = Yes (Y) there is Central Air, or 0 = No Central Air. The other categorical columns will get a dummy column for N-1 categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur0gV8YnDCJT"
      },
      "source": [
        "data = data[['Id', 'LotArea', 'BldgType', 'HouseStyle', 'YearBuilt', 'Heating', 'CentralAir', 'FullBath',\n",
        "               'HalfBath', 'Fireplaces', 'GarageArea', 'PoolArea', 'YrSold', 'SalePrice']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ivSw7Yvr5M"
      },
      "source": [
        "cat_cols = ['BldgType', 'HouseStyle', 'Heating', 'CentralAir']\n",
        "dummies = [pd.get_dummies(data[x], drop_first=True) for x in cat_cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69EBLCblwNl_"
      },
      "source": [
        "dummies = pd.concat(dummies, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0FKrUKt0O3j"
      },
      "source": [
        "data.drop(cat_cols, axis=1, inplace=True)\n",
        "data = pd.concat([data, dummies], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwpStRUg3MrF"
      },
      "source": [
        "# must omit a column with a random NaN and from the true values\n",
        "omit_col = data.index[data.isna().any(axis=1)]\n",
        "data = data.drop(omit_col, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "-CcDmEAK5esu",
        "outputId": "6f801ff7-dccd-498e-acdd-16094bb81094"
      },
      "source": [
        "data.reset_index(inplace=True, drop=True)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>2fmCon</th>\n",
              "      <th>Duplex</th>\n",
              "      <th>Twnhs</th>\n",
              "      <th>TwnhsE</th>\n",
              "      <th>1.5Unf</th>\n",
              "      <th>1Story</th>\n",
              "      <th>2.5Fin</th>\n",
              "      <th>2.5Unf</th>\n",
              "      <th>2Story</th>\n",
              "      <th>SFoyer</th>\n",
              "      <th>SLvl</th>\n",
              "      <th>GasA</th>\n",
              "      <th>GasW</th>\n",
              "      <th>Grav</th>\n",
              "      <th>OthW</th>\n",
              "      <th>Wall</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>8450</td>\n",
              "      <td>2003</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>548.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>208500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>9600</td>\n",
              "      <td>1976</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>460.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2007</td>\n",
              "      <td>181500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>11250</td>\n",
              "      <td>2001</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>608.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>223500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>9550</td>\n",
              "      <td>1915</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>642.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>140000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>14260</td>\n",
              "      <td>2000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>836.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>250000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2912</th>\n",
              "      <td>2915</td>\n",
              "      <td>1936</td>\n",
              "      <td>1970</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>90500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2913</th>\n",
              "      <td>2916</td>\n",
              "      <td>1894</td>\n",
              "      <td>1970</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>71000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2914</th>\n",
              "      <td>2917</td>\n",
              "      <td>20000</td>\n",
              "      <td>1960</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>576.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>131000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2915</th>\n",
              "      <td>2918</td>\n",
              "      <td>10441</td>\n",
              "      <td>1992</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>132000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2916</th>\n",
              "      <td>2919</td>\n",
              "      <td>9627</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>650.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>188000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2917 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  LotArea  YearBuilt  FullBath  HalfBath  ...  GasW  Grav  OthW  Wall  Y\n",
              "0        1     8450       2003         2         1  ...     0     0     0     0  1\n",
              "1        2     9600       1976         2         0  ...     0     0     0     0  1\n",
              "2        3    11250       2001         2         1  ...     0     0     0     0  1\n",
              "3        4     9550       1915         1         0  ...     0     0     0     0  1\n",
              "4        5    14260       2000         2         1  ...     0     0     0     0  1\n",
              "...    ...      ...        ...       ...       ...  ...   ...   ...   ...   ... ..\n",
              "2912  2915     1936       1970         1         1  ...     0     0     0     0  1\n",
              "2913  2916     1894       1970         1         1  ...     0     0     0     0  1\n",
              "2914  2917    20000       1960         1         0  ...     0     0     0     0  1\n",
              "2915  2918    10441       1992         1         0  ...     0     0     0     0  1\n",
              "2916  2919     9627       1993         2         1  ...     0     0     0     0  1\n",
              "\n",
              "[2917 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTfXPHlHW5eo"
      },
      "source": [
        "y = data['SalePrice']\n",
        "X = data.drop(['SalePrice', 'Id'], axis=1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def trainSets(x_data, y_data, test_size):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        x_data, y_data,\n",
        "        test_size=test_size, train_size=1-test_size,\n",
        "        random_state=611, shuffle=True)\n",
        "    return x_train, x_test, y_train, y_test\n",
        "\n",
        "split_dat = trainSets(X, y, .2)\n",
        "x_train = split_dat[0]\n",
        "x_test = split_dat[1]\n",
        "y_train = split_dat[2]\n",
        "y_test = split_dat[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "8VRDJiMuYVbU",
        "outputId": "ad547ccf-1683-4a09-9d93-7ba4ef9159a9"
      },
      "source": [
        "display(x_train, x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LotArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>2fmCon</th>\n",
              "      <th>Duplex</th>\n",
              "      <th>Twnhs</th>\n",
              "      <th>TwnhsE</th>\n",
              "      <th>1.5Unf</th>\n",
              "      <th>1Story</th>\n",
              "      <th>2.5Fin</th>\n",
              "      <th>2.5Unf</th>\n",
              "      <th>2Story</th>\n",
              "      <th>SFoyer</th>\n",
              "      <th>SLvl</th>\n",
              "      <th>GasA</th>\n",
              "      <th>GasW</th>\n",
              "      <th>Grav</th>\n",
              "      <th>OthW</th>\n",
              "      <th>Wall</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1564</th>\n",
              "      <td>20062</td>\n",
              "      <td>1977</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>690.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1909</th>\n",
              "      <td>13607</td>\n",
              "      <td>1986</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>501.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>8529</td>\n",
              "      <td>2001</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>527.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>3182</td>\n",
              "      <td>2004</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>430.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470</th>\n",
              "      <td>1680</td>\n",
              "      <td>1971</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1792</th>\n",
              "      <td>8010</td>\n",
              "      <td>1958</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>7399</td>\n",
              "      <td>1997</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>576.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2007</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>13214</td>\n",
              "      <td>2008</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>746.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>8450</td>\n",
              "      <td>1965</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>336.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2205</th>\n",
              "      <td>9670</td>\n",
              "      <td>1935</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>786.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2333 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      LotArea  YearBuilt  FullBath  HalfBath  ...  Grav  OthW  Wall  Y\n",
              "1564    20062       1977         1         1  ...     0     0     0  1\n",
              "1909    13607       1986         2         1  ...     0     0     0  1\n",
              "827      8529       2001         2         0  ...     0     0     0  1\n",
              "385      3182       2004         2         0  ...     0     0     0  1\n",
              "1470     1680       1971         1         1  ...     0     0     0  1\n",
              "...       ...        ...       ...       ...  ...   ...   ...   ... ..\n",
              "1792     8010       1958         1         0  ...     0     0     0  1\n",
              "297      7399       1997         2         1  ...     0     0     0  1\n",
              "1266    13214       2008         2         0  ...     0     0     0  1\n",
              "698      8450       1965         1         0  ...     0     0     0  1\n",
              "2205     9670       1935         1         1  ...     0     0     0  1\n",
              "\n",
              "[2333 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LotArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>2fmCon</th>\n",
              "      <th>Duplex</th>\n",
              "      <th>Twnhs</th>\n",
              "      <th>TwnhsE</th>\n",
              "      <th>1.5Unf</th>\n",
              "      <th>1Story</th>\n",
              "      <th>2.5Fin</th>\n",
              "      <th>2.5Unf</th>\n",
              "      <th>2Story</th>\n",
              "      <th>SFoyer</th>\n",
              "      <th>SLvl</th>\n",
              "      <th>GasA</th>\n",
              "      <th>GasW</th>\n",
              "      <th>Grav</th>\n",
              "      <th>OthW</th>\n",
              "      <th>Wall</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>10295</td>\n",
              "      <td>1969</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2880</th>\n",
              "      <td>8170</td>\n",
              "      <td>1929</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>451.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>5790</td>\n",
              "      <td>1915</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>379.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503</th>\n",
              "      <td>8000</td>\n",
              "      <td>2002</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>596.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2619</th>\n",
              "      <td>9783</td>\n",
              "      <td>1996</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>443.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2848</th>\n",
              "      <td>21533</td>\n",
              "      <td>1996</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>467.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>7200</td>\n",
              "      <td>1910</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>9042</td>\n",
              "      <td>1941</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>252.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>11060</td>\n",
              "      <td>2003</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>502.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>10200</td>\n",
              "      <td>1925</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>584 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      LotArea  YearBuilt  FullBath  HalfBath  ...  Grav  OthW  Wall  Y\n",
              "1958    10295       1969         1         0  ...     0     0     0  1\n",
              "2880     8170       1929         2         0  ...     0     0     0  1\n",
              "74       5790       1915         2         0  ...     0     0     0  0\n",
              "1503     8000       2002         2         0  ...     0     0     0  1\n",
              "2619     9783       1996         2         1  ...     0     0     0  1\n",
              "...       ...        ...       ...       ...  ...   ...   ...   ... ..\n",
              "2848    21533       1996         2         1  ...     0     0     0  1\n",
              "1013     7200       1910         1         0  ...     0     0     0  0\n",
              "1456     9042       1941         2         0  ...     0     0     0  1\n",
              "2861    11060       2003         2         1  ...     0     0     0  1\n",
              "1912    10200       1925         1         0  ...     0     0     0  0\n",
              "\n",
              "[584 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAqn69jpzSTk"
      },
      "source": [
        "# this function will perform a monte carlo validation to test the true accuracy of the optimized model\n",
        "def monte_carlo_valid(model, dat, response, pct_data_split=0.8):\n",
        "    # randomly split data\n",
        "    inds = np.random.rand(len(X)) < pct_data_split\n",
        "    x_train = dat[inds]\n",
        "    x_test = dat[~inds]\n",
        "    y_train = response[inds]\n",
        "    y_test = response[~inds]\n",
        "\n",
        "    ypred = model.predict(x_test)\n",
        "    \n",
        "    df = {'Explained_Variance': [np.round(explained_variance_score(y_test, ypred),5)],\n",
        "          'Max_Error': [np.round(max_error(y_test, ypred),5)],\n",
        "          'MSE': [np.round(mean_squared_error(y_test, ypred),5)],\n",
        "          'MAE': [np.round(mean_absolute_error(y_test, ypred),5)]}\n",
        "    df = pd.DataFrame(data=df)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8oOGtq9-_XC"
      },
      "source": [
        "# Elastic Net\n",
        "\n",
        "The first model I'll build is a 5-Fold Cross-Validated Elastic Net Regression. You'll see the [Explained Variance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score), [Max Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error), [Mean-Absolute-Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error), and [Mean-Squared-Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) printed as the results for each model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NutRrgN7Z_o7"
      },
      "source": [
        "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error\n",
        "def eval_metrics(y_true, y_pred):\n",
        "  print('Explained Variance: ', np.round(explained_variance_score(y_true, y_pred),2))\n",
        "  print('Max Error: ', np.round(max_error(y_true, y_pred),2))\n",
        "  print('MSE: ', np.round(mean_squared_error(y_true, y_pred),2))\n",
        "  print('MAE: ', np.round(mean_absolute_error(y_true, y_pred),2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCVVaVx3t9D9",
        "outputId": "d4ca4ae6-6337-43c2-a770-560b7ea9719d"
      },
      "source": [
        "from sklearn.linear_model import ElasticNetCV\n",
        "eNet = ElasticNetCV(cv=5, random_state=0)\n",
        "eNet.fit(x_train, y_train)\n",
        "eNet_preds = eNet.predict(x_test)\n",
        "eval_metrics(y_test, eNet_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained Variance:  0.2\n",
            "Max Error:  532117.39\n",
            "MSE:  5037233739.27\n",
            "MAE:  51517.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3QYYxCx_75p"
      },
      "source": [
        "The Elastic Net does not perform well by any metric on the testing data. We can validate these results by running the Monte-Carlo validation function built above. I'll run the simulation 50 times with 20% of the data reserved for testing each time. The function simply refits the model to a new training sample and tests on a new testing split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "4v9Ls33g0Yo_",
        "outputId": "2e355426-6c90-42e9-ece9-22cf808117c7"
      },
      "source": [
        "# run the monte carlo function 50 times\n",
        "results = [monte_carlo_valid(eNet, X, y) for p in range(0,50)]\n",
        "# concat all rows into one df\n",
        "results = pd.concat(results, axis=0)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "results.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Explained_Variance</th>\n",
              "      <th>Max_Error</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.20</td>\n",
              "      <td>437087.39</td>\n",
              "      <td>5159789100.13</td>\n",
              "      <td>51400.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.02</td>\n",
              "      <td>83187.18</td>\n",
              "      <td>591356393.98</td>\n",
              "      <td>1963.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.17</td>\n",
              "      <td>269009.62</td>\n",
              "      <td>4126127874.38</td>\n",
              "      <td>46959.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.19</td>\n",
              "      <td>368918.89</td>\n",
              "      <td>4702250273.50</td>\n",
              "      <td>49681.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.20</td>\n",
              "      <td>414043.84</td>\n",
              "      <td>5177912530.75</td>\n",
              "      <td>51716.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.22</td>\n",
              "      <td>532117.39</td>\n",
              "      <td>5579762288.69</td>\n",
              "      <td>52528.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.25</td>\n",
              "      <td>536404.39</td>\n",
              "      <td>6810428887.20</td>\n",
              "      <td>57828.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Explained_Variance  Max_Error           MSE      MAE\n",
              "count               50.00      50.00         50.00    50.00\n",
              "mean                 0.20  437087.39 5159789100.13 51400.32\n",
              "std                  0.02   83187.18  591356393.98  1963.03\n",
              "min                  0.17  269009.62 4126127874.38 46959.44\n",
              "25%                  0.19  368918.89 4702250273.50 49681.18\n",
              "50%                  0.20  414043.84 5177912530.75 51716.95\n",
              "75%                  0.22  532117.39 5579762288.69 52528.77\n",
              "max                  0.25  536404.39 6810428887.20 57828.10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-kJzM3CBQh5"
      },
      "source": [
        "The Elastic Net's poor results were not fluke. The error ranges were consistent with what we saw above. The model was only able to explain ~20% of the variance in SalePrice and the average prediction was off by over $50,000. Let's see how that compares to other models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdg0L3G82zon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ccd4c9-8a53-49dc-a760-16f80c381390"
      },
      "source": [
        "from sklearn import linear_model\n",
        "reg = linear_model.LinearRegression()\n",
        "reg.fit(x_train, y_train)\n",
        "print('R^2: ', reg.score(x_train, y_train))\n",
        "lin_mod_preds = reg.predict(x_test)\n",
        "eval_metrics(y_test, lin_mod_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2:  0.6500159994811975\n",
            "Explained Variance:  0.63\n",
            "Max Error:  409893.2\n",
            "MSE:  2323348538.56\n",
            "MAE:  33742.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq50s4GCF558"
      },
      "source": [
        "# OLS Regression\n",
        "\n",
        "A simple OLS Regression appears to outperform the Elastic Net. I've displayed the R-Squared for context and to display the difference between it and the Explained Variance, which are slightly different calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "WuQ6QWd63aJ_",
        "outputId": "1c3e07f1-c063-4179-8997-cbad0580a6d3"
      },
      "source": [
        "# run the monte carlo function 50 times\n",
        "results = [monte_carlo_valid(reg, X, y) for p in range(0,50)]\n",
        "# concat all rows into one df\n",
        "results = pd.concat(results, axis=0)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "results.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Explained_Variance</th>\n",
              "      <th>Max_Error</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.65</td>\n",
              "      <td>322992.09</td>\n",
              "      <td>2259569678.05</td>\n",
              "      <td>33120.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.02</td>\n",
              "      <td>59023.80</td>\n",
              "      <td>321131874.50</td>\n",
              "      <td>1414.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.59</td>\n",
              "      <td>174095.77</td>\n",
              "      <td>1660454175.41</td>\n",
              "      <td>30567.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.63</td>\n",
              "      <td>296657.79</td>\n",
              "      <td>2041824091.39</td>\n",
              "      <td>32117.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.65</td>\n",
              "      <td>308809.08</td>\n",
              "      <td>2193046462.68</td>\n",
              "      <td>32810.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.66</td>\n",
              "      <td>379200.38</td>\n",
              "      <td>2427688916.14</td>\n",
              "      <td>34002.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.70</td>\n",
              "      <td>409893.20</td>\n",
              "      <td>3259978353.33</td>\n",
              "      <td>37543.74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Explained_Variance  Max_Error           MSE      MAE\n",
              "count               50.00      50.00         50.00    50.00\n",
              "mean                 0.65  322992.09 2259569678.05 33120.51\n",
              "std                  0.02   59023.80  321131874.50  1414.66\n",
              "min                  0.59  174095.77 1660454175.41 30567.45\n",
              "25%                  0.63  296657.79 2041824091.39 32117.63\n",
              "50%                  0.65  308809.08 2193046462.68 32810.25\n",
              "75%                  0.66  379200.38 2427688916.14 34002.43\n",
              "max                  0.70  409893.20 3259978353.33 37543.74"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLvmI5KDGVIi"
      },
      "source": [
        "The simulation proves that the OLS is more effective than the simple implementation of the Elastic Net. However, there's still plenty of room to improve on for more refined models. Next I'll show the results of a K-Nearest Neighbor Regression.\n",
        "\n",
        "# K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uzr_-wGfflw"
      },
      "source": [
        "def bestParams(model):\n",
        "    best_params = model.best_params_\n",
        "    return best_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqrR04LLcX37",
        "outputId": "f6ff0bcf-dcf4-4f35-8567-5e26290e536d"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "knn = KNeighborsRegressor()\n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "parameters = {'n_neighbors': [3,5,7,10,15,20],\n",
        "              'weights': ['uniform', 'distance']}\n",
        "\n",
        "knn = GridSearchCV(knn, parameters, cv=5, scoring='neg_mean_squared_error', refit=True)\n",
        "knn.fit(x_train, y_train)\n",
        "knn_preds = knn.predict(x_test)\n",
        "eval_metrics(y_test, knn_preds)\n",
        "print('Optimal Parameters: ', bestParams(knn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained Variance:  0.48\n",
            "Max Error:  567706.76\n",
            "MSE:  3264175811.66\n",
            "MAE:  37958.34\n",
            "Optimal Parameters:  {'n_neighbors': 10, 'weights': 'distance'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GDfxsY4JSyu"
      },
      "source": [
        "Through a Cross-Validated Grid Search I've tuned the number of neighbors and weights parameters in order to optimize the Mean Squared Error. 10 neighbors is the best number from the options provided, and a non-uniform weighting of those neighbors improves predictive accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ukbz0iDS3ni-",
        "outputId": "fe98e5a7-6a78-43fb-e3b1-eb8a6db36524"
      },
      "source": [
        "# run the monte carlo function 50 times\n",
        "results = [monte_carlo_valid(knn, X, y) for p in range(0,50)]\n",
        "# concat all rows into one df\n",
        "results = pd.concat(results, axis=0)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "results.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Explained_Variance</th>\n",
              "      <th>Max_Error</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.89</td>\n",
              "      <td>279347.82</td>\n",
              "      <td>702993425.64</td>\n",
              "      <td>7894.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.04</td>\n",
              "      <td>157032.02</td>\n",
              "      <td>305674249.84</td>\n",
              "      <td>1036.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.80</td>\n",
              "      <td>127747.62</td>\n",
              "      <td>331219239.54</td>\n",
              "      <td>5810.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.88</td>\n",
              "      <td>183136.50</td>\n",
              "      <td>512889617.47</td>\n",
              "      <td>7108.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.91</td>\n",
              "      <td>226928.95</td>\n",
              "      <td>582659737.02</td>\n",
              "      <td>7790.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.92</td>\n",
              "      <td>228038.54</td>\n",
              "      <td>736942224.35</td>\n",
              "      <td>8573.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.95</td>\n",
              "      <td>567706.76</td>\n",
              "      <td>1416517014.00</td>\n",
              "      <td>10791.99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Explained_Variance  Max_Error           MSE      MAE\n",
              "count               50.00      50.00         50.00    50.00\n",
              "mean                 0.89  279347.82  702993425.64  7894.19\n",
              "std                  0.04  157032.02  305674249.84  1036.20\n",
              "min                  0.80  127747.62  331219239.54  5810.26\n",
              "25%                  0.88  183136.50  512889617.47  7108.09\n",
              "50%                  0.91  226928.95  582659737.02  7790.60\n",
              "75%                  0.92  228038.54  736942224.35  8573.12\n",
              "max                  0.95  567706.76 1416517014.00 10791.99"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGX0mqJqJqWK"
      },
      "source": [
        "Our Monte-Carlo simulation shows fantastic improves for KNN over OLS and Elastic Net. Every metric improved substantially. Now we turn our attention to the focus of this assignment, Random Forest and Boosting algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXTlKwXpiTBI"
      },
      "source": [
        "# Random Forest\n",
        "I'll tune the number of estimators, max depth of a tree, and the minimium number of samples required to form a split parameters. For the sake of training time I've chosen a fairly limited range of values for each of these parameters. These are chosen via a Cross-Validated Grid Search over a list of values.\n",
        "\n",
        "I included each of the default values in each of the ranges to display how these values are oft not optimal. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y553SLolhhts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1869bb35-de3d-4eda-8943-ae6b08378a8e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(random_state=33)\n",
        "rf.fit(x_train, y_train)\n",
        "\n",
        "parameters = {'n_estimators': [50,75,100,200],\n",
        "              'max_depth': [2,5,10,15],\n",
        "              'min_samples_split': [2,25,50,100]}\n",
        "\n",
        "rf = GridSearchCV(rf, parameters, cv=5, scoring='neg_mean_squared_error', refit=True)\n",
        "rf.fit(x_train, y_train)\n",
        "rf_preds = rf.predict(x_test)\n",
        "eval_metrics(y_test, rf_preds)\n",
        "print('Optimal Parameters: ', bestParams(rf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained Variance:  0.75\n",
            "Max Error:  269778.24\n",
            "MSE:  1555339494.02\n",
            "MAE:  25541.02\n",
            "Optimal Parameters:  {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "vChWzNyu3qib",
        "outputId": "be21c6a8-5587-46f0-c148-9b28974b75d5"
      },
      "source": [
        "# run the monte carlo function 50 times\n",
        "results = [monte_carlo_valid(rf, X, y) for p in range(0,50)]\n",
        "# concat all rows into one df\n",
        "results = pd.concat(results, axis=0)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "results.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Explained_Variance</th>\n",
              "      <th>Max_Error</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.92</td>\n",
              "      <td>174497.53</td>\n",
              "      <td>482034100.69</td>\n",
              "      <td>12920.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.01</td>\n",
              "      <td>51742.74</td>\n",
              "      <td>76172999.12</td>\n",
              "      <td>612.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.90</td>\n",
              "      <td>116503.76</td>\n",
              "      <td>350651069.07</td>\n",
              "      <td>11617.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.92</td>\n",
              "      <td>131088.32</td>\n",
              "      <td>428576959.90</td>\n",
              "      <td>12570.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.92</td>\n",
              "      <td>175367.69</td>\n",
              "      <td>474470014.75</td>\n",
              "      <td>12950.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.93</td>\n",
              "      <td>192201.26</td>\n",
              "      <td>532922470.69</td>\n",
              "      <td>13354.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.95</td>\n",
              "      <td>269778.24</td>\n",
              "      <td>691481298.33</td>\n",
              "      <td>14304.89</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Explained_Variance  Max_Error          MSE      MAE\n",
              "count               50.00      50.00        50.00    50.00\n",
              "mean                 0.92  174497.53 482034100.69 12920.24\n",
              "std                  0.01   51742.74  76172999.12   612.16\n",
              "min                  0.90  116503.76 350651069.07 11617.82\n",
              "25%                  0.92  131088.32 428576959.90 12570.01\n",
              "50%                  0.92  175367.69 474470014.75 12950.82\n",
              "75%                  0.93  192201.26 532922470.69 13354.38\n",
              "max                  0.95  269778.24 691481298.33 14304.89"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llOHdePIkTnq"
      },
      "source": [
        "The parameter tuning method found that building 200 estimators (2x the default value). While building more trees, it also found that building the deepest trees from the range of values given would be optimal. So, the Forest consists of 200 models with a maximum depth of 15.\n",
        "\n",
        "Interestingly, the results are mixed in comparison to the best performing baseline model (KNN). The Random Forest's Explained Variance is marginally better, and a Max Error that is lower by almost $100,000. This could indicate that the Random Forest's predictions are not as far off as the KNN's. This idea is supported by the Random Forest's lower MSE. However, KNN provides a better MAE. MSE will punish larger error more harshly. Therefore, the KNN algorithm is more prone to predict a number very close or very far off to the actual SalePrice. The Random Forest is off by more, on average, but it is not prone to substantially inaccurate predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5Yp563eo69i",
        "outputId": "edb12ce6-2662-4c06-d0a6-cb8656380402"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gb = GradientBoostingRegressor(random_state=25)\n",
        "gb.fit(x_train, y_train)\n",
        "\n",
        "parameters = {'n_estimators': [50,75,100,200],\n",
        "              'learning_rate': [.01, .05, .1, .2],\n",
        "              'max_depth': [3, 6, 10, 15],\n",
        "              'subsample': [.25, .5, .75, 1]}\n",
        "\n",
        "gb = GridSearchCV(gb, parameters, cv=5, scoring='neg_mean_squared_error', refit=True)\n",
        "gb.fit(x_train, y_train)\n",
        "gb_preds = gb.predict(x_test)\n",
        "eval_metrics(y_test, gb_preds)\n",
        "print('Optimal Parameters: ', bestParams(gb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained Variance:  0.75\n",
            "Max Error:  235602.41\n",
            "MSE:  1577888155.28\n",
            "MAE:  26121.41\n",
            "Optimal Parameters:  {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.75}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ijkkkrOM3tT2",
        "outputId": "5012a291-733c-42fe-891e-fca608ca0c1f"
      },
      "source": [
        "# run the monte carlo function 50 times\n",
        "results = [monte_carlo_valid(gb, X, y) for p in range(0,50)]\n",
        "# concat all rows into one df\n",
        "results = pd.concat(results, axis=0)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "results.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Explained_Variance</th>\n",
              "      <th>Max_Error</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>50.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.90</td>\n",
              "      <td>178151.52</td>\n",
              "      <td>659337267.04</td>\n",
              "      <td>17655.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.02</td>\n",
              "      <td>40531.70</td>\n",
              "      <td>76231109.08</td>\n",
              "      <td>689.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.86</td>\n",
              "      <td>96894.71</td>\n",
              "      <td>529143541.80</td>\n",
              "      <td>15906.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.88</td>\n",
              "      <td>162795.32</td>\n",
              "      <td>605240958.86</td>\n",
              "      <td>17287.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.90</td>\n",
              "      <td>173520.65</td>\n",
              "      <td>659197683.78</td>\n",
              "      <td>17557.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.90</td>\n",
              "      <td>204104.67</td>\n",
              "      <td>705184481.11</td>\n",
              "      <td>18104.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.93</td>\n",
              "      <td>235602.41</td>\n",
              "      <td>859691237.86</td>\n",
              "      <td>19371.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Explained_Variance  Max_Error          MSE      MAE\n",
              "count               50.00      50.00        50.00    50.00\n",
              "mean                 0.90  178151.52 659337267.04 17655.86\n",
              "std                  0.02   40531.70  76231109.08   689.68\n",
              "min                  0.86   96894.71 529143541.80 15906.78\n",
              "25%                  0.88  162795.32 605240958.86 17287.72\n",
              "50%                  0.90  173520.65 659197683.78 17557.94\n",
              "75%                  0.90  204104.67 705184481.11 18104.03\n",
              "max                  0.93  235602.41 859691237.86 19371.86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfy9xUJuoNcm"
      },
      "source": [
        "# Gradient-Boosted Regressor\n",
        "\n",
        "For my Gradient-Boosted Regressor I tuned the number of estimators, learning rate, max tree depth, and the fraction of samples to use for base learners (subsample). Learning rate and subsample must be tuned if n_estimators is tuned as they tend to interact with the number of estimators. Although n_estimators remained at the default value, the learning rate and subsample decreased through the grid search. Learning rate shrinks the contribution of an individual tree, so a lower learning rate decreases the impact of a single tree. This balances the decrease in subsample from its default value. As subsample decreases variances reduces and bias increases as subsample lowers the fraction of samples being used. The ratio between these two was more optimal than the default values provided in the baseline model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy0VR9xSuCzD"
      },
      "source": [
        "Counter to my expectation, the Gradient-Boosted model did not outperform the 'simple' Random Forest. Its comparison to the KNN model was similar to the Random Forest's. But, the Gradient-Boosted model posted a higher MAE, MSE, and max error when compared to the Random Forest. So, it was missing by a wider margin and more often than the Random Forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XApjeC9um-R"
      },
      "source": [
        " # Final Comparison\n",
        "\n",
        "While the Random Forest and Gradient-Boosted Regressor outperformed the Elastic Net and Linear Regression, their results were not substantially better than an optimized K-Nearest Neighbor approach. While KNN may not be considered a true 'baseline' model, one would expect a Random Forest or GBR to be more predictive than KNN. I suspect KNN is a very good approach for this dataset as KNN functions similar to how a human prices a house. An agent walks through a house and points out the number of bathrooms and square-footage then shows a price comparison to houses with similar attributes. Because of the similarity between house pricing based on home characteristics and KNN predicting based on the best 'comparisons' nearest to a house in question the KNN algorithm is uniquely suited to fit the needs of this dataset. For instance, KNN predicts the same way a human would as a house with two bathrooms and 2,000 square feet would be expected to be priced very similarly. This is very easy to detect with a KNN approach as the prediction is based on the most similar neighbors. However, the difference between ensemble methods and KNN was not terribly significant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ueZb07x_gs",
        "outputId": "7c961385-479b-4119-b26b-2bd857d294a7"
      },
      "source": [
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "!pip install pypandoc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "pandoc is already the newest version (1.19.2.4~dfsg-1build4).\n",
            "pandoc set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-latex-base\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  fonts-noto apache2 | lighttpd | httpd poppler-utils ghostscript\n",
            "  fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri\n",
            "  ruby-dev bundler debhelper gv | postscript-viewer perl-tk xpdf-reader\n",
            "  | pdf-viewer texlive-fonts-recommended-doc texlive-latex-base-doc\n",
            "  python-pygments icc-profiles libfile-which-perl\n",
            "  libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks dot2tex prerex ruby-tcltk\n",
            "  | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-latex-base\n",
            "  texlive-latex-extra texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic texlive-xetex tipa\n",
            "0 upgraded, 47 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 146 MB of archives.\n",
            "After this operation, 460 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.14 [5,092 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [2,265 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Err:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.7\n",
            "  404  Not Found [IP: 91.189.88.152 80]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Err:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.7\n",
            "  404  Not Found [IP: 91.189.88.152 80]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive all 2017.20180305-1 [14.4 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-xetex all 2017.20180305-1 [10.7 MB]\n",
            "Fetched 143 MB in 8s (17.2 MB/s)\n",
            "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/r/ruby2.5/ruby2.5_2.5.1-1ubuntu1.7_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n",
            "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/r/ruby2.5/libruby2.5_2.5.1-1ubuntu1.7_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "Collecting pypandoc\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/b7/5050dc1769c8a93d3ec7c4bd55be161991c94b8b235f88bf7c764449e708/pypandoc-1.5.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pypandoc) (54.1.2)\n",
            "Requirement already satisfied: pip>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from pypandoc) (19.3.1)\n",
            "Requirement already satisfied: wheel>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from pypandoc) (0.36.2)\n",
            "Building wheels for collected packages: pypandoc\n",
            "  Building wheel for pypandoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypandoc: filename=pypandoc-1.5-cp37-none-any.whl size=17036 sha256=a5d035dd1c54d955781cd7d03eea6bf6544abbc346161576a5d7067b0d187763\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/7d/d6/2f9af55e800d37e42e546106bcbd36a86e24e725e303d17e04\n",
            "Successfully built pypandoc\n",
            "Installing collected packages: pypandoc\n",
            "Successfully installed pypandoc-1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rkeuHebyABS",
        "outputId": "b97870cf-901c-4033-b143-edad1c47376f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVVjGmj0yEU8",
        "outputId": "b9d846cc-b413-4705-b40f-137613279602"
      },
      "source": [
        "!jupyter nbconvert --to PDF \"hw6_rf_boosting.ipynb\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] WARNING | pattern u'hw6_rf_boosting.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb) to various other\n",
            "formats.\n",
            "\n",
            "WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "-------\n",
            "\n",
            "Arguments that take values are actually convenience aliases to full\n",
            "Configurables, whose aliases are listed on the help line. For more information\n",
            "on full configurables, see '--help-all'.\n",
            "\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document. \n",
            "    This mode is ideal for generating code-free reports.\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only \n",
            "    relevant when converting to notebook format)\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "--clear-output\n",
            "    Clear output of current file and save in place, \n",
            "    overwriting the existing notebook.\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "--generate-config\n",
            "    generate default config file\n",
            "--nbformat=<Enum> (NotebookExporter.nbformat_version)\n",
            "    Default: 4\n",
            "    Choices: [1, 2, 3, 4]\n",
            "    The nbformat version to write. Use this to downgrade notebooks.\n",
            "--output-dir=<Unicode> (FilesWriter.build_directory)\n",
            "    Default: ''\n",
            "    Directory to write output(s) to. Defaults to output to the directory of each\n",
            "    notebook. To recover previous default behaviour (outputting to the current\n",
            "    working directory) use . as the flag value.\n",
            "--writer=<DottedObjectName> (NbConvertApp.writer_class)\n",
            "    Default: 'FilesWriter'\n",
            "    Writer class used to write the  results of the conversion\n",
            "--log-level=<Enum> (Application.log_level)\n",
            "    Default: 30\n",
            "    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\n",
            "    Set the log level by value or name.\n",
            "--reveal-prefix=<Unicode> (SlidesExporter.reveal_url_prefix)\n",
            "    Default: u''\n",
            "    The URL prefix for reveal.js (version 3.x). This defaults to the reveal CDN,\n",
            "    but can be any url pointing to a copy  of reveal.js.\n",
            "    For speaker notes to work, this must be a relative path to a local  copy of\n",
            "    reveal.js: e.g., \"reveal.js\".\n",
            "    If a relative path is given, it must be a subdirectory of the current\n",
            "    directory (from which the server is run).\n",
            "    See the usage documentation\n",
            "    (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-\n",
            "    slideshow) for more details.\n",
            "--to=<Unicode> (NbConvertApp.export_format)\n",
            "    Default: 'html'\n",
            "    The export format to be used, either one of the built-in formats\n",
            "    ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf',\n",
            "    'python', 'rst', 'script', 'slides'] or a dotted object name that represents\n",
            "    the import path for an `Exporter` class\n",
            "--template=<Unicode> (TemplateExporter.template_file)\n",
            "    Default: u''\n",
            "    Name of the template file to use\n",
            "--output=<Unicode> (NbConvertApp.output_base)\n",
            "    Default: ''\n",
            "    overwrite base name use for output files. can only be used when converting\n",
            "    one notebook at a time.\n",
            "--post=<DottedOrNone> (NbConvertApp.postprocessor_class)\n",
            "    Default: u''\n",
            "    PostProcessor class used to write the results of the conversion\n",
            "--config=<Unicode> (JupyterApp.config_file)\n",
            "    Default: u''\n",
            "    Full path of a config file.\n",
            "\n",
            "To see all available configurables, use `--help-all`\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb\n",
            "    \n",
            "    which will convert mynotebook.ipynb to the default format (probably HTML).\n",
            "    \n",
            "    You can specify the export format with `--to`.\n",
            "    Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\n",
            "    \n",
            "    > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "    \n",
            "    Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
            "    can specify the flavor of the format used.\n",
            "    \n",
            "    > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
            "    \n",
            "    You can also pipe the output to stdout, rather than a file\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "    \n",
            "    PDF is generated via latex\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "    \n",
            "    You can get (and serve) a Reveal.js-powered slideshow\n",
            "    \n",
            "    > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "    \n",
            "    Multiple notebooks can be given at the command line in a couple of \n",
            "    different ways:\n",
            "    \n",
            "    > jupyter nbconvert notebook*.ipynb\n",
            "    > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "    \n",
            "    or you can specify the notebooks list in a config file, containing::\n",
            "    \n",
            "        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "    \n",
            "    > jupyter nbconvert --config mycfg.py\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OjhaOH-yUhQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}